{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2f14170e9f314ae0968c4ad54df2fc59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0f0f2cbe24144d4db2a5b8fa3d5b5de3",
              "IPY_MODEL_07a0739cb9d743cf91e7c3b775af4f4c",
              "IPY_MODEL_90204ccf8af34a04a96ba6e9e4398ade"
            ],
            "layout": "IPY_MODEL_e95fa4a7635840db87e143d497abe411"
          }
        },
        "0f0f2cbe24144d4db2a5b8fa3d5b5de3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34a8f73931ef4878b6e8fd3383286e4e",
            "placeholder": "​",
            "style": "IPY_MODEL_8b68134e2d934500af4348f7bda25d1a",
            "value": "Map: 100%"
          }
        },
        "07a0739cb9d743cf91e7c3b775af4f4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a28210029b7a479ab5881ac80c25e1b0",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_358d5420026d477283f1b8e867328746",
            "value": 10
          }
        },
        "90204ccf8af34a04a96ba6e9e4398ade": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1872d1eb44f40be925d11ceae4e7386",
            "placeholder": "​",
            "style": "IPY_MODEL_a097f48fd5e448dc8fa8da6d5db8e97f",
            "value": " 10/10 [00:00&lt;00:00, 367.79 examples/s]"
          }
        },
        "e95fa4a7635840db87e143d497abe411": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34a8f73931ef4878b6e8fd3383286e4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b68134e2d934500af4348f7bda25d1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a28210029b7a479ab5881ac80c25e1b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "358d5420026d477283f1b8e867328746": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a1872d1eb44f40be925d11ceae4e7386": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a097f48fd5e448dc8fa8da6d5db8e97f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rohittkr/Building_Machine_Translation_using_llm/blob/main/sunilsaumya1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMDx3stQimba",
        "outputId": "02c7026c-71bc-4ec6-e65c-0af8d26b6716"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFMarianMTModel.\n",
            "\n",
            "All the layers of TFMarianMTModel were initialized from the model checkpoint at Helsinki-NLP/opus-mt-en-hi.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMarianMTModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: I am opening the cupboard\n",
            "Translated: मैं कपबोर्ड खोल रहा हूँ\n"
          ]
        }
      ],
      "source": [
        "# Install required libraries\n",
        "!pip install datasets transformers[sentencepiece] -q\n",
        "\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from transformers import AutoTokenizer, TFAutoModelForSeq2SeqLM\n",
        "\n",
        "# Load the model and tokenizer for zero-shot translation\n",
        "model_checkpoint = \"Helsinki-NLP/opus-mt-en-hi\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "model = TFAutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n",
        "\n",
        "# Example sentence for zero-shot translation\n",
        "input_text = \"I am opening the cupboard\"\n",
        "\n",
        "# Tokenize the input text\n",
        "tokenized = tokenizer([input_text], return_tensors='np')\n",
        "\n",
        "# Generate the translated output\n",
        "out = model.generate(**tokenized, max_length=128)\n",
        "\n",
        "# Decode the generated output to text\n",
        "with tokenizer.as_target_tokenizer():\n",
        "    decoded_output = tokenizer.decode(out[0], skip_special_tokens=True)\n",
        "\n",
        "print(f\"Input: {input_text}\")\n",
        "print(f\"Translated: {decoded_output}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the necessary dependencies\n",
        "!pip install tensorflow transformers datasets sacrebleu -q\n",
        "\n",
        "import tensorflow as tf\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, TFAutoModelForSeq2SeqLM\n",
        "from transformers import DataCollatorForSeq2Seq, AdamWeightDecay\n",
        "\n",
        "# Load pre-trained model and tokenizer for translation task\n",
        "model_checkpoint = \"Helsinki-NLP/opus-mt-en-hi\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "\n",
        "# Load the dataset (replace 'cfilt/iitb-english-hindi' with your dataset name)\n",
        "raw_datasets = load_dataset(\"cfilt/iitb-english-hindi\")\n",
        "\n",
        "# Preview the dataset\n",
        "print(\"Raw Dataset:\", raw_datasets)\n",
        "\n",
        "# Define the max length for input and target text\n",
        "max_input_length = 128\n",
        "max_target_length = 128\n",
        "source_lang = \"en\"\n",
        "target_lang = \"hi\"\n",
        "\n",
        "# Preprocessing function to tokenize inputs and targets\n",
        "def preprocess_function(examples):\n",
        "    inputs = [ex[source_lang] for ex in examples[\"translation\"]]\n",
        "    targets = [ex[target_lang] for ex in examples[\"translation\"]]\n",
        "\n",
        "    # Tokenize inputs\n",
        "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True, padding=\"max_length\")\n",
        "\n",
        "    # Tokenize targets with target tokenizer\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(targets, max_length=max_target_length, truncation=True, padding=\"max_length\")\n",
        "\n",
        "    # Add labels to the model input (for supervised learning)\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs\n",
        "\n",
        "# Select a small sample for few-shot learning (e.g., first 10 examples)\n",
        "few_shot_dataset = raw_datasets[\"train\"].select(range(10))\n",
        "\n",
        "# Apply the preprocessing function on the few-shot dataset\n",
        "tokenized_datasets = few_shot_dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "# Check the tokenized dataset\n",
        "print(\"Tokenized Few-Shot Samples (First 2):\", tokenized_datasets[:2])\n",
        "\n",
        "# Prepare TensorFlow dataset for training from the tokenized few-shot dataset\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=None, return_tensors=\"tf\")\n",
        "\n",
        "train_dataset = model.prepare_tf_dataset(\n",
        "    tokenized_datasets,\n",
        "    batch_size=2,  # Small batch size for few-shot training\n",
        "    shuffle=True,\n",
        "    collate_fn=data_collator,\n",
        ")\n",
        "\n",
        "# Check if the train dataset is properly created\n",
        "print(\"Train Dataset Length:\", len(train_dataset))  # This should be > 0 if data is present\n",
        "\n",
        "# Optionally, inspect the first batch in the dataset\n",
        "for batch in train_dataset.take(1):  # Take first batch\n",
        "    print(\"Batch:\", batch)\n",
        "\n",
        "# Load the model (Helsinki-NLP/opus-mt-en-hi)\n",
        "model = TFAutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n",
        "\n",
        "# Define optimizer and compile the model\n",
        "optimizer = AdamWeightDecay(learning_rate=2e-5, weight_decay_rate=0.01)\n",
        "model.compile(optimizer=optimizer)\n",
        "\n",
        "# Fine-tune the model with the few-shot dataset (training for 1 epoch)\n",
        "model.fit(train_dataset, epochs=1)\n",
        "\n",
        "# Save the fine-tuned model\n",
        "model.save_pretrained(\"fine_tuned_model/\")\n",
        "tokenizer.save_pretrained(\"fine_tuned_model/\")\n",
        "\n",
        "# Reload the fine-tuned model and tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"fine_tuned_model/\")\n",
        "model = TFAutoModelForSeq2SeqLM.from_pretrained(\"fine_tuned_model/\")\n",
        "\n",
        "# Example sentence to translate\n",
        "input_text = \"I am going to the swimming pool.\"\n",
        "\n",
        "# Tokenize the input sentence\n",
        "tokenized_input = tokenizer([input_text], return_tensors='np')\n",
        "\n",
        "# Generate the translation\n",
        "generated_output = model.generate(**tokenized_input, max_length=128)\n",
        "\n",
        "# Decode the translated output\n",
        "decoded_output = tokenizer.decode(generated_output[0], skip_special_tokens=True)\n",
        "\n",
        "print(f\"Input: {input_text}\")\n",
        "print(f\"Translated: {decoded_output}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "2f14170e9f314ae0968c4ad54df2fc59",
            "0f0f2cbe24144d4db2a5b8fa3d5b5de3",
            "07a0739cb9d743cf91e7c3b775af4f4c",
            "90204ccf8af34a04a96ba6e9e4398ade",
            "e95fa4a7635840db87e143d497abe411",
            "34a8f73931ef4878b6e8fd3383286e4e",
            "8b68134e2d934500af4348f7bda25d1a",
            "a28210029b7a479ab5881ac80c25e1b0",
            "358d5420026d477283f1b8e867328746",
            "a1872d1eb44f40be925d11ceae4e7386",
            "a097f48fd5e448dc8fa8da6d5db8e97f"
          ]
        },
        "id": "OB5yjI_PtJZA",
        "outputId": "75bf92d9-c0f5-4fc2-9912-17841da35d28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw Dataset: DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['translation'],\n",
            "        num_rows: 1659083\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['translation'],\n",
            "        num_rows: 520\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['translation'],\n",
            "        num_rows: 2507\n",
            "    })\n",
            "})\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2f14170e9f314ae0968c4ad54df2fc59"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenized Few-Shot Samples (First 2): {'translation': [{'en': 'Give your application an accessibility workout', 'hi': 'अपने अनुप्रयोग को पहुंचनीयता व्यायाम का लाभ दें'}, {'en': 'Accerciser Accessibility Explorer', 'hi': 'एक्सेर्साइसर पहुंचनीयता अन्वेषक'}], 'input_ids': [[3872, 85, 2501, 132, 15441, 36398, 0, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949], [32643, 28541, 36253, 0, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'labels': [[63, 2025, 18, 16155, 346, 20311, 24, 2279, 679, 0, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949], [26618, 16155, 346, 33383, 0, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949]]}\n",
            "Train Dataset Length: 5\n",
            "Batch: ({'input_ids': <tf.Tensor: shape=(2, 128), dtype=int64, numpy=\n",
            "array([[   81,  1724,  1907,  6461,    34,     4,  3346, 10061,     0,\n",
            "        61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949,\n",
            "        61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949,\n",
            "        61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949,\n",
            "        61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949,\n",
            "        61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949,\n",
            "        61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949,\n",
            "        61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949,\n",
            "        61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949,\n",
            "        61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949,\n",
            "        61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949,\n",
            "        61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949,\n",
            "        61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949,\n",
            "        61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949,\n",
            "        61949, 61949],\n",
            "       [ 6941,  2740,  3111,     0, 61949, 61949, 61949, 61949, 61949,\n",
            "        61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949,\n",
            "        61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949,\n",
            "        61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949,\n",
            "        61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949,\n",
            "        61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949,\n",
            "        61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949,\n",
            "        61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949,\n",
            "        61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949,\n",
            "        61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949,\n",
            "        61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949,\n",
            "        61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949,\n",
            "        61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949,\n",
            "        61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949,\n",
            "        61949, 61949]])>, 'attention_mask': <tf.Tensor: shape=(2, 128), dtype=int64, numpy=\n",
            "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])>}, <tf.Tensor: shape=(2, 128), dtype=int64, numpy=\n",
            "array([[ 6704, 12422,     6,    39, 22433, 10076,    69,  4553,  7788,\n",
            "            0, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949,\n",
            "        61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949,\n",
            "        61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949,\n",
            "        61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949,\n",
            "        61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949,\n",
            "        61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949,\n",
            "        61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949,\n",
            "        61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949,\n",
            "        61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949,\n",
            "        61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949,\n",
            "        61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949,\n",
            "        61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949,\n",
            "        61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949,\n",
            "        61949, 61949],\n",
            "       [  870,  4011,     6,   593,    18, 10866,    84,     0, 61949,\n",
            "        61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949,\n",
            "        61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949,\n",
            "        61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949,\n",
            "        61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949,\n",
            "        61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949,\n",
            "        61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949,\n",
            "        61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949,\n",
            "        61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949,\n",
            "        61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949,\n",
            "        61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949,\n",
            "        61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949,\n",
            "        61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949,\n",
            "        61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949, 61949,\n",
            "        61949, 61949]])>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFMarianMTModel.\n",
            "\n",
            "All the layers of TFMarianMTModel were initialized from the model checkpoint at Helsinki-NLP/opus-mt-en-hi.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMarianMTModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 17s 95ms/step - loss: 0.1635\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/configuration_utils.py:393: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
            "Non-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[61949]]}\n",
            "  warnings.warn(\n",
            "All model checkpoint layers were used when initializing TFMarianMTModel.\n",
            "\n",
            "All the layers of TFMarianMTModel were initialized from the model checkpoint at fine_tuned_model/.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMarianMTModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: I am going to the swimming pool.\n",
            "Translated: मैं तालाब के लिए जा रहा हूँ.\n"
          ]
        }
      ]
    }
  ]
}